{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1766beb",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(context='paper', style='ticks')\n",
    "\n",
    "from utils import load_json, save_json\n",
    "\n",
    "# --------------------------\n",
    "# Helper Functions\n",
    "# --------------------------\n",
    "\n",
    "def round_to_first_of_next_month(dt):\n",
    "    \"\"\"\n",
    "    Round a datetime.date or datetime.datetime to the first day\n",
    "    of the *following* month at midnight (returns pandas.Timestamp).\n",
    "    \"\"\"\n",
    "    year = dt.year\n",
    "    month = dt.month + 1 if dt.month < 12 else 1\n",
    "    year = year if month != 1 else year + 1\n",
    "    return pd.to_datetime(f'{year}-{month:02d}-01')\n",
    "\n",
    "\n",
    "def find_minimum_date_for_endpoint(df, endpoint, trend, ltv, htv, min_entries=100):\n",
    "    \"\"\"\n",
    "    Returns the first date (after at least `min_entries` records)\n",
    "    where the endpoint measurement satisfies the optimum condition.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Contains 'SMILES', 'DATE', and endpoint columns.\n",
    "        endpoint (str): Endpoint column name.\n",
    "        trend (str): 'H', 'L', or 'V' for high, low, or value range optimal.\n",
    "        ltv (float): Lower threshold value.\n",
    "        htv (float): Higher threshold value.\n",
    "        min_entries (int): Number of entries before checking condition.\n",
    "\n",
    "    Returns:\n",
    "        pd.Timestamp or None\n",
    "    \"\"\"\n",
    "    temp_df = df[['SMILES', 'DATE', endpoint]].copy()\n",
    "    temp_df = temp_df.sort_values('DATE').drop_duplicates('SMILES').dropna().reset_index(drop=True)\n",
    "\n",
    "    for i, row in temp_df.iterrows():\n",
    "        if i >= min_entries:\n",
    "            value = row[endpoint]\n",
    "            if (\n",
    "                (trend == 'H' and value >= ltv) or\n",
    "                (trend == 'L' and value <= htv) or\n",
    "                (trend == 'V' and ltv <= value <= htv)\n",
    "            ):\n",
    "                return row['DATE']\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_bs(nb_available_to_select, batch_size=0.5):\n",
    "    \"\"\"\n",
    "    Determines how many samples to select based on batch size setting.\n",
    "\n",
    "    Parameters:\n",
    "        nb_available_to_select (int): Total number of available items.\n",
    "        batch_size (float or int): Fraction (0<batch_size<1) or absolute value (>1).\n",
    "\n",
    "    Returns:\n",
    "        int: Number of samples to select.\n",
    "    \"\"\"\n",
    "    if 0 <= batch_size < 1:\n",
    "        return max(1, round(batch_size * nb_available_to_select)) if nb_available_to_select > 0 else 0\n",
    "    elif batch_size >= 1:\n",
    "        return min(nb_available_to_select, int(batch_size))\n",
    "    else:\n",
    "        raise ValueError(\"batch_size must be >= 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802c3d1",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38faff2",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the dataset name from the current working directory\n",
    "DATASET = os.getcwd().split('/')[-1]\n",
    "\n",
    "# Define base path for dataset\n",
    "data_path = f'../../data/{DATASET}'\n",
    "\n",
    "# Load the main and aggregated data\n",
    "data_df = pd.read_csv(f'{data_path}/data.csv').sort_values(by='DATE').reset_index(drop=True)\n",
    "df = pd.read_csv(f'{data_path}/data_aggregated.csv').sort_values(by='DATE').reset_index(drop=True)\n",
    "\n",
    "# Load blueprint data\n",
    "bp_df = pd.read_csv(f'{data_path}/blueprint.csv')\n",
    "\n",
    "# Convert 'DATE' column to datetime for proper time handling\n",
    "data_df['DATE'] = pd.to_datetime(data_df['DATE'])\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "# Extract endpoints from blueprint\n",
    "endpoints = bp_df['PROPERTIES'].values\n",
    "\n",
    "# Load simulation configuration\n",
    "common_config = load_json('../../data/common/datasets_config.json')\n",
    "\n",
    "# Display config info if available\n",
    "if DATASET in common_config:\n",
    "    cfg = common_config[DATASET]\n",
    "    print(f\"{DATASET} already in the configuration file, with the following parameters :\")\n",
    "    print(f\"    dataset      : {DATASET}\")\n",
    "    print(f\"    initial_date : {cfg['initial_date']}\")\n",
    "    print(f\"    final_date   : {cfg['final_date']}\")\n",
    "    print(f\"    timestep     : {cfg['timestep']}\")\n",
    "\n",
    "# ⚠️⚠️⚠️ If manual override is needed to determine minimum date, put it in the next line under the YYYY-MM-DD format, else None ⚠️⚠️⚠️\n",
    "MINIMUM_DATE = None\n",
    "\n",
    "# Plot distribution of experimental assays over time\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "sns.histplot(data_df['DATE'], bins=50, ax=ax)\n",
    "ax.set_title(f\"{DATASET} | Distribution of Experimental Assays\")\n",
    "\n",
    "\n",
    "if MINIMUM_DATE is not None:\n",
    "    # Convert MINIMUM_DATE to pandas datetime\n",
    "    MINIMUM_DATE = pd.to_datetime(MINIMUM_DATE)\n",
    "    ax.axvline(x=MINIMUM_DATE, color='red', linestyle='--', label=f'Minimum date : {MINIMUM_DATE.date()}')\n",
    "    ax.legend() \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c7acc4",
   "metadata": {},
   "source": [
    "### Defining simulations parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Constants and Parameters\n",
    "# --------------------------\n",
    "TIMESTEP = 1   # in months\n",
    "BATCH_SIZE = 0.5 # fraction or int\n",
    "\n",
    "# --------------------------\n",
    "# Compute Minimum Valid Dates for Each Endpoint\n",
    "# --------------------------\n",
    "minimum_dates = {}\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    try:\n",
    "        # Retrieve the properties for the endpoint from bp_df\n",
    "        endpoint_row = bp_df.loc[bp_df['PROPERTIES'] == endpoint]\n",
    "        \n",
    "        if endpoint_row.empty:\n",
    "            print(f\"Warning: No properties found for endpoint '{endpoint}' in bp_df. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        props = endpoint_row[['TREND', 'LTV', 'HTV', 'WEIGHT']].squeeze()\n",
    "        trend = props['TREND']\n",
    "        lower_acceptable_value = props['LTV']\n",
    "        higher_acceptable_value = props['HTV']\n",
    "        \n",
    "        # Use the helper function on the full data_df\n",
    "        min_date = find_minimum_date_for_endpoint(\n",
    "            data_df, endpoint, trend, lower_acceptable_value, higher_acceptable_value\n",
    "        )\n",
    "        \n",
    "        if min_date is not None:\n",
    "            minimum_dates[endpoint] = min_date\n",
    "        else:\n",
    "            print(f\"Warning: Could not determine minimum date for endpoint '{endpoint}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing endpoint '{endpoint}': {str(e)}\")\n",
    "\n",
    "# Create a DataFrame from the dictionary for inspection if needed\n",
    "minimum_dates_df = (\n",
    "    pd.DataFrame.from_dict(minimum_dates, orient='index', columns=['MINIMUM_DATE'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'ENDPOINT'})  # Using uppercase for consistency\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Determine Simulation Dates\n",
    "# --------------------------\n",
    "# Choose the main endpoint (the one with the most complete data)\n",
    "main_endpoint = df[endpoints].count().idxmax()\n",
    "print(f\"Selected '{main_endpoint}' as the main endpoint based on data completeness\")\n",
    "\n",
    "if main_endpoint in minimum_dates:\n",
    "    minimum_date_main = minimum_dates[main_endpoint]\n",
    "    \n",
    "    # Set the simulation starting date based on the main endpoint;\n",
    "    # then round to the first day of the next month.\n",
    "    starting_date = round_to_first_of_next_month(minimum_date_main)\n",
    "    \n",
    "    if MINIMUM_DATE is not None and starting_date < pd.to_datetime(MINIMUM_DATE):\n",
    "        print(f\"⚠️ Starting date {starting_date.date()} is set to the minimum date {MINIMUM_DATE.date()}\")\n",
    "        starting_date = pd.to_datetime(MINIMUM_DATE)\n",
    "    else: \n",
    "        print(f\"Simulation starting date set to: {starting_date}\")\n",
    "else:\n",
    "    raise ValueError(f\"Main endpoint '{main_endpoint}' does not have a minimum date\")\n",
    "\n",
    "# The simulation ends at the latest date in df.\n",
    "ending_date = df['DATE'].max()\n",
    "print(f\"Simulation ending date set to: {ending_date.date()}\")\n",
    "\n",
    "# --------------------------\n",
    "# Filter Endpoints by Pre-Simulation Data\n",
    "# --------------------------\n",
    "# Find endpoints with at least 100 molecules documented before starting_date\n",
    "pre_simulation_data = data_df[data_df['DATE'] < starting_date]\n",
    "endpoint_counts = pre_simulation_data[endpoints].count()\n",
    "endpoints_with_sufficient_data = endpoint_counts[endpoint_counts >= 100].index\n",
    "nb_endpoints_with_sufficient_data = len(endpoints_with_sufficient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1efdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Determine Endpoints with Compounds in Optimum Range\n",
    "# --------------------------\n",
    "# Pre-compute filtered dataframe once (more efficient)\n",
    "pre_simulation_df = data_df[data_df['DATE'] < starting_date].copy()\n",
    "\n",
    "valid_endpoints = []\n",
    "for endpoint in endpoints_with_sufficient_data:\n",
    "    try:\n",
    "        endpoint_row = bp_df.loc[bp_df['PROPERTIES'] == endpoint]\n",
    "        \n",
    "        if endpoint_row.empty:\n",
    "            print(f\"Warning: No properties found for endpoint '{endpoint}' in bp_df. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        props = endpoint_row[['TREND', 'LTV', 'HTV', 'WEIGHT']].squeeze()\n",
    "        trend = props['TREND']\n",
    "        lower_acceptable_value = props['LTV']  # Lower Acceptable Value\n",
    "        higher_acceptable_value = props['HTV']  # Higher Acceptable Value\n",
    "        \n",
    "        # Check if at least one compound is in optimum range\n",
    "        if find_minimum_date_for_endpoint(pre_simulation_df, endpoint, trend, \n",
    "                                          lower_acceptable_value, higher_acceptable_value) is not None:\n",
    "            valid_endpoints.append(endpoint)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing endpoint '{endpoint}': {str(e)}\")\n",
    "\n",
    "nb_valid_endpoints = len(valid_endpoints)\n",
    "print(f\"Found {nb_valid_endpoints} endpoints with at least one compound in optimum range\")\n",
    "\n",
    "# --------------------------\n",
    "# Monthly Molecule Counts After Simulation Start\n",
    "# --------------------------\n",
    "# Count unique molecules per month after simulation start\n",
    "monthly_counts = (\n",
    "    df[df['DATE'] >= starting_date][['SMILES', 'DATE']]\n",
    "    .copy()\n",
    "    .set_index('DATE')\n",
    "    .resample('ME')  # Month End frequency\n",
    "    .size()\n",
    ")\n",
    "print(f\"Created monthly counts for {len(monthly_counts)} months after simulation start\")\n",
    "\n",
    "# --------------------------\n",
    "# Compute Time Buckets and Prepare Simulation\n",
    "# --------------------------\n",
    "# Calculate number of iterations more directly\n",
    "simulation_months = ((ending_date.year - starting_date.year) * 12 + \n",
    "                    ending_date.month - starting_date.month)\n",
    "nb_iterations = (simulation_months // TIMESTEP) + (1 if simulation_months % TIMESTEP > 0 else 0)\n",
    "\n",
    "# Filter data for simulation period\n",
    "simulation_df = df[df['DATE'] >= starting_date].copy()\n",
    "nb_initial = df.shape[0] - simulation_df.shape[0]\n",
    "\n",
    "# Create month-based integer representation for bucketing\n",
    "simulation_df['year_month_int'] = simulation_df['DATE'].dt.year * 12 + simulation_df['DATE'].dt.month\n",
    "\n",
    "# Create time buckets based on TIMESTEP\n",
    "simulation_df['time_bucket'] = (simulation_df['year_month_int'] - \n",
    "                              (starting_date.year * 12 + starting_date.month)) // TIMESTEP\n",
    "\n",
    "# Count compounds per time bucket\n",
    "timestep_counts = simulation_df.groupby('time_bucket').size()\n",
    "\n",
    "# Ensure all buckets exist (fill gaps with zeros)\n",
    "full_buckets = range(0, nb_iterations)\n",
    "timestep_counts = timestep_counts.reindex(full_buckets, fill_value=0)\n",
    "\n",
    "# Create human-readable labels for time buckets\n",
    "labels = []\n",
    "start_month_num = starting_date.year * 12 + starting_date.month\n",
    "for bucket in timestep_counts.index:\n",
    "    month_num = start_month_num + (bucket * TIMESTEP)\n",
    "    year = month_num // 12\n",
    "    month = month_num % 12\n",
    "    if month == 0:\n",
    "        year -= 1\n",
    "        month = 12\n",
    "    labels.append(f\"{year}-{month:02d}\")\n",
    "\n",
    "timestep_counts.index = labels\n",
    "\n",
    "# Calculate batch sizes for each time period\n",
    "simulation_bs = [get_bs(count, batch_size=BATCH_SIZE) for count in timestep_counts]\n",
    "\n",
    "# Verify our calculations match\n",
    "assert len(timestep_counts) == nb_iterations, f\"Expected {nb_iterations} timesteps but got {len(timestep_counts)}\"\n",
    "\n",
    "# --------------------------\n",
    "# Simulation: Tracking Compound Selection\n",
    "# --------------------------\n",
    "# Initialize tracking variables\n",
    "df['iteration'] = 0  # Add column to track when compounds enter the simulation\n",
    "already_selected = 0\n",
    "already_selected_list = []\n",
    "selected_at_iteration_list = []\n",
    "iterations = []\n",
    "\n",
    "# Perform simulation over time periods\n",
    "current_date = starting_date\n",
    "for iteration in range(1, nb_iterations + 1):\n",
    "    iterations.append(iteration)\n",
    "    next_date = current_date + relativedelta(months=TIMESTEP)\n",
    "    \n",
    "    # Tag compounds in current time window with iteration number\n",
    "    mask = (df['DATE'] >= current_date) & (df['DATE'] < next_date)\n",
    "    df.loc[mask, 'iteration'] = iteration\n",
    "    \n",
    "    # Calculate statistics\n",
    "    available_since_start = len(df[(df['DATE'] >= starting_date) & (df['DATE'] < next_date)])\n",
    "    available_for_selection = available_since_start - already_selected\n",
    "    \n",
    "    # Record selected compounds for this iteration\n",
    "    selected = simulation_bs[iteration - 1]\n",
    "    already_selected += selected\n",
    "    \n",
    "    # Track progress\n",
    "    selected_at_iteration_list.append(selected)\n",
    "    already_selected_list.append(already_selected)\n",
    "    \n",
    "    current_date = next_date\n",
    "\n",
    "# Calculate final statistics\n",
    "nb_final_selected = already_selected_list[-1] if already_selected_list else 0\n",
    "nb_initially = df[df['DATE'] < starting_date]['SMILES'].nunique()\n",
    "nb_total_smiles = df['SMILES'].nunique()\n",
    "\n",
    "print(f\"Initially available compounds: {nb_initially}\")\n",
    "print(f\"Total unique compounds: {nb_total_smiles}\")\n",
    "print(f\"Final selected compounds: {nb_final_selected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71189b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Summary Output\n",
    "# --------------------------\n",
    "try:\n",
    "    # Helper function for safe date formatting\n",
    "    def safe_date_format(date_obj):\n",
    "        \"\"\"Safely format a date object, handling None values.\"\"\"\n",
    "        if pd.isna(date_obj):\n",
    "            return \"Not available\"\n",
    "        return date_obj.date()\n",
    "\n",
    "    # Create visual separators\n",
    "    separator = \"-\" * 80\n",
    "    \n",
    "    # Project overview section\n",
    "    print(separator)\n",
    "    print(\"PROJECT OVERVIEW\")\n",
    "    print(separator)\n",
    "    print(f\"Number of molecules in project: {nb_total_smiles:,}\")\n",
    "    print(f\"The main endpoint is: {main_endpoint}\")\n",
    "    print(f\"The minimum date when the main endpoint is documented on at least 100 molecules: \"\n",
    "          f\"{safe_date_format(minimum_date_main)}\")\n",
    "\n",
    "    # Simulation parameters\n",
    "    print(f\"\\n{separator}\")\n",
    "    print(\"SIMULATION PARAMETERS\")\n",
    "    print(separator)\n",
    "    print(f\"Simulation starting date: {safe_date_format(starting_date)}\")\n",
    "    print(f\"Simulation ending date: {safe_date_format(ending_date)}\")\n",
    "    print(f\"Timestep: {TIMESTEP} month(s)\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "    # Pre-simulation statistics\n",
    "    print(f\"\\n{separator}\")\n",
    "    print(\"PRE-SIMULATION STATISTICS\")\n",
    "    print(separator)\n",
    "    print(f\"Molecules available before simulation start: {nb_initially:,}\")\n",
    "    \n",
    "    # Display endpoints with sufficient data\n",
    "    print(f\"Endpoints with ≥100 molecules documented: {nb_endpoints_with_sufficient_data}\")\n",
    "    if nb_endpoints_with_sufficient_data > 0:\n",
    "        endpoint_list = sorted(list(endpoints_with_sufficient_data))\n",
    "        if len(endpoint_list) <= 10:\n",
    "            print(f\"  List: {', '.join(endpoint_list)}\")\n",
    "        else:\n",
    "            print(f\"  First 10: {', '.join(endpoint_list[:10])}...\")\n",
    "    \n",
    "    # Display endpoints with optimum range\n",
    "    print(f\"Endpoints with ≥100 molecules documented AND at least one in optimum range: \"\n",
    "          f\"{nb_valid_endpoints}\")\n",
    "    if nb_valid_endpoints > 0:\n",
    "        valid_endpoint_list = sorted(list(valid_endpoints))\n",
    "        if len(valid_endpoint_list) <= 10:\n",
    "            print(f\"  List: {', '.join(valid_endpoint_list)}\")\n",
    "        else:\n",
    "            print(f\"  First 10: {', '.join(valid_endpoint_list[:10])}...\")\n",
    "\n",
    "    # Monthly statistics\n",
    "    print(f\"\\n{separator}\")\n",
    "    print(\"MONTHLY MOLECULE STATISTICS\")\n",
    "    print(separator)\n",
    "    \n",
    "    if not monthly_counts.empty:\n",
    "        print(f\"Median molecules per month: {round(monthly_counts.median()):,}\")\n",
    "        print(f\"Mean molecules per month: {round(monthly_counts.mean()):,}\")\n",
    "        print(f\"Standard deviation: {round(monthly_counts.std()):,}\")\n",
    "    else:\n",
    "        print(\"No monthly data available.\")\n",
    "\n",
    "    # Simulation results\n",
    "    print(f\"\\n{separator}\")\n",
    "    print(\"SIMULATION RESULTS\")\n",
    "    print(separator)\n",
    "    print(f\"Number of iterations (TIMESTEP = {TIMESTEP} month(s)): {nb_iterations}\")\n",
    "    \n",
    "    # Calculate exploration percentages\n",
    "    percentage_total = round(100 * (nb_final_selected + nb_initially) / nb_total_smiles)\n",
    "    percentage_initial = round(100 * nb_initially / nb_total_smiles)\n",
    "    percentage_selected = round(100 * nb_final_selected / nb_total_smiles)\n",
    "    \n",
    "    print(f\"Percentage of molecules explored with batch size {BATCH_SIZE}:\")\n",
    "    print(f\"  Initial:  {percentage_initial}%\")\n",
    "    print(f\"  Selected: {percentage_selected}%\")\n",
    "    print(f\"  Total:    {percentage_total}%\")\n",
    "    \n",
    "    print(separator)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating summary output: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Plotting Results\n",
    "# --------------------------\n",
    "fig, ax = plt.subplots(\n",
    "    1, 2, \n",
    "    figsize=(15, 5)  # First ax is twice as wide as the second\n",
    ")\n",
    "\n",
    "sns.histplot(df['DATE'], bins=100, ax=ax[0], zorder=1)\n",
    "ax[0].axvspan(starting_date, ending_date, color='green', alpha=0.33, label='Simulation period', zorder=0)\n",
    "\n",
    "if 'ANN' in df.columns:\n",
    "    ann_dates = []\n",
    "    for i, ann in enumerate(df[~df['ANN'].isna()]['ANN'].unique()):\n",
    "        ann_dates = df[df['ANN'] == ann]['DATE'].unique()\n",
    "\n",
    "        for ann_date in ann_dates:\n",
    "            ax[0].axvline(ann_date, linestyle='--', color=['red', 'green', 'blue'][i], label=f'ANN : {ann}', zorder=2)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(f\"{DATASET} | Project timeline\")\n",
    "\n",
    "sns.lineplot(df['iteration'].value_counts(sort=False).drop(0).cumsum(), linewidth=2, label='Cumsum compouds in the project (excluding the initial ones)', ax=ax[1])\n",
    "sns.lineplot(x=iterations, y=already_selected_list, linewidth=2, label=f'Cumsum selected compounds in a simulation', ax=ax[1])\n",
    "sns.lineplot(x=iterations, y=np.array(iterations) * 24, linestyle='--', linewidth=2, label=f'Theoretical maximum cumulative sum of selected compound', ax=ax[1])\n",
    "\n",
    "ax[1].set_title(f\"{DATASET} : Cumulative sum of compounds (TIMESTEP = {TIMESTEP}, BATCH SIZE = {BATCH_SIZE})\");\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"🆕 Parameters :\")\n",
    "print(f\"    initial_date : {str(starting_date).split(' ')[0]}\")\n",
    "print(f\"    final_date   : {str(ending_date).split(' ')[0]}\")\n",
    "print(f\"    timestep     : {TIMESTEP}\")\n",
    "\n",
    "parameters = {\n",
    "    'initial_date': str(starting_date).split(' ')[0],\n",
    "    'final_date': str(ending_date).split(' ')[0],\n",
    "    'timestep': TIMESTEP\n",
    "}\n",
    "\n",
    "if DATASET in common_config.keys():\n",
    "\n",
    "    old_parameters = common_config[DATASET]\n",
    "\n",
    "    if old_parameters != parameters:\n",
    "        print(f\"⚠️ {DATASET} already in the configuration file, with different parameters :\")\n",
    "        print(f\"    initial_date : {common_config[DATASET]['initial_date']}\")\n",
    "        print(f\"    final_date   : {common_config[DATASET]['final_date']}\")\n",
    "        print(f\"    timestep     : {common_config[DATASET]['timestep']}\")\n",
    "\n",
    "        print(f\"\\n⚠️ If you run the following cell, it will save the new parameters ! \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace the config with newly defined parameters\n",
    "# common_config[DATASET] = parameters\n",
    "# save_json(common_config, f'../../data/common/datasets_config.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311cu120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
